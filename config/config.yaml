language: "ru"

models:
  ru:
    backend: "llama.cpp"
    model_path: "./models/saiga_llama3_8b-q4_k_m.gguf"
    n_ctx: 8192
  en:
    backend: "transformers"
    model_name: "mistralai/Mistral-7B-Instruct-v0.1"

embedding_model: "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"

retriever:
  top_k: 6
  similarity_metric: "cosine"

reranker:
  use_reranker: true
  top_k: 3

# Размер одного чанка в токенах и перекрытия
chunk_size_tokens: 100
chunk_overlap_tokens: 20
